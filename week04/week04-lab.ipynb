{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edeb77ff",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "# **Spring 2026 &mdash; CIS 3813<br>Advanced Data Science<br>(Introduction to Machine Learning)**\n",
    "### Week 4: Multi-Feature Regression — Standard vs. Ridge vs. Lasso\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e21911",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Lab Instructions**\n",
    "\n",
    "**Due Date**: Monday, 23 February @ 6:00 PM (with grace period until Wednesday, 25 February @ 11:59 PM)\n",
    "\n",
    "In this lab, you will apply what you learned to a different dataset: a synthetic dataset mirroring the structure of the Ames Housing dataset (a more detailed housing dataset from Ames, Iowa). You will:\n",
    "\n",
    "1. Load and explore the data\n",
    "2. Prepare features and handle scaling\n",
    "3. Fit Standard, Ridge, and Lasso regression models\n",
    "4. Compare performance and interpret coefficients\n",
    "5. Explore the effect of alpha on Lasso's feature selection\n",
    "\n",
    "\n",
    "**AI Usage**: \n",
    "- You may use AI tools for this lab\n",
    "- **REQUIRED**: Include AI attribution using the format shown in the syllabus\n",
    "- For B/A level credit, include detailed attribution in markdown cells\n",
    "\n",
    "## **Grading**\n",
    "\n",
    "| Component | Points |\n",
    "|-----------|--------|\n",
    "| Exercise 1: Load and Explore the Data | 10 |\n",
    "| Exercise 2: Prepare the Data | 15 |\n",
    "| Exercise 3: Fit and Compare Three Models | 30 |\n",
    "| Exercise 4: Alpha Exploration | 25 |\n",
    "| Exercise 5: Reflection | 10 |\n",
    "| In-Class Mastery Assessment (Week 5) | 10 |\n",
    "| **Total** | **100** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c5f602",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **AI Assistance Declaration**\n",
    "\n",
    "**Tools used:** [ChatGPT-4 / GitHub Copilot / Claude / None / Other — update this]\n",
    "\n",
    "**Sections with AI help:** [e.g., \"Part 2, Question 3\" — update this]\n",
    "\n",
    "**What I learned:** [Brief description — update this]\n",
    "\n",
    "**What I did independently:** [Sections completed without AI — update this]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bc5158",
   "metadata": {},
   "source": [
    "# **Configuring Our Environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b5b231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SETUP — Run this first\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plots below may contain warnings. Uncomment these two lines to suppress them.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8658b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== RUN THIS CELL TO GENERATE THE LAB DATASET =====\n",
    "# This creates a realistic housing dataset for our lab\n",
    "\n",
    "np.random.seed(42)\n",
    "n = 1000\n",
    "\n",
    "# Generate correlated housing features\n",
    "sq_ft = np.random.normal(1800, 500, n).clip(600, 5000)\n",
    "bedrooms = np.round(1 + sq_ft / 700 + np.random.normal(0, 0.5, n)).clip(1, 7).astype(int)\n",
    "bathrooms = np.round(0.5 + bedrooms * 0.6 + np.random.normal(0, 0.3, n), 1).clip(1, 5)\n",
    "lot_size = np.random.normal(8000, 3000, n).clip(2000, 30000)\n",
    "year_built = np.random.randint(1950, 2024, n)\n",
    "garage_cars = np.random.choice([0, 1, 2, 3], n, p=[0.05, 0.25, 0.55, 0.15])\n",
    "overall_quality = np.round(3 + sq_ft / 1000 + np.random.normal(0, 1, n)).clip(1, 10).astype(int)\n",
    "neighborhood_score = np.random.uniform(1, 10, n)  # 1-10 desirability\n",
    "\n",
    "# Noisy/irrelevant features (these SHOULD get zeroed out by Lasso)\n",
    "fence_type = np.random.randint(0, 5, n)           # Mostly irrelevant to price\n",
    "month_sold = np.random.randint(1, 13, n)           # Weak seasonal effect\n",
    "misc_feature_val = np.random.exponential(50, n)    # Random noise\n",
    "\n",
    "# Generate target: Sale Price (with realistic relationships)\n",
    "sale_price = (\n",
    "    200 * sq_ft\n",
    "    + 15000 * bathrooms\n",
    "    + 7500 * bedrooms\n",
    "    + 1 * lot_size\n",
    "    - 1000 * (2025 - year_built)\n",
    "    + 1000 * garage_cars\n",
    "    + 15000 * overall_quality\n",
    "    + 20000 * neighborhood_score\n",
    "    + 100 * fence_type              # Very small effect\n",
    "    + 25 * month_sold               # Negligible effect\n",
    "    + 0 * misc_feature_val          # Zero effect (pure noise)\n",
    "    + np.random.normal(0, 2500, n)  # Random noise\n",
    ")\n",
    "\n",
    "# Create DataFrame\n",
    "ames_df = pd.DataFrame({\n",
    "    'SqFt': sq_ft.round(0),\n",
    "    'Bedrooms': bedrooms,\n",
    "    'Bathrooms': bathrooms,\n",
    "    'LotSize': lot_size.round(0),\n",
    "    'YearBuilt': year_built,\n",
    "    'GarageCars': garage_cars,\n",
    "    'OverallQuality': overall_quality,\n",
    "    'NeighborhoodScore': neighborhood_score.round(2),\n",
    "    'FenceType': fence_type,\n",
    "    'MonthSold': month_sold,\n",
    "    'MiscFeatureVal': misc_feature_val.round(2),\n",
    "    'SalePrice': sale_price.round(0)\n",
    "})\n",
    "\n",
    "print(f\"Dataset created: {ames_df.shape[0]} houses, {ames_df.shape[1] - 1} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76969818",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Exercise 1: Load and Explore the Data (10 points)**\n",
    "\n",
    "### **Task 1a: Explore the dataset (5 points)**\n",
    "\n",
    "Run `.describe()` on the dataset and write a brief Markdown observation about the **range/scale differences** between features. Which features have the largest range? Which have the smallest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192a173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE — use .describe() and examine the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b9073e",
   "metadata": {},
   "source": [
    "*YOUR OBSERVATIONS HERE (double-click to edit):*\n",
    "\n",
    "- **Largest ranges:** \n",
    "- **Smallest ranges:** \n",
    "- **Implication:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d807a5e",
   "metadata": {},
   "source": [
    "### **Task 1b: Visualize feature correlations with the target (5 points)**\n",
    "\n",
    "Create a **correlation heatmap** or bar chart showing how each feature correlates with `SalePrice`. Which features appear most/least correlated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abe1985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE — compute and visualize correlations with SalePrice\n",
    "# Hint: ames_df.corr()['SalePrice'].sort_values()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83803d72",
   "metadata": {},
   "source": [
    "*MOST/LEAST Correlated Features*\n",
    "\n",
    "- **Most Correlated:** \n",
    "- **Least Corrleted:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d83190",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Exercise 2: Prepare the Data (15 points)**\n",
    "\n",
    "### **Task 2a: Split into features (X) and target (y), then train/test split (5 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eb4e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# 1. Separate features (X) and target (y = SalePrice)\n",
    "# 2. Split into 80% train / 20% test with random_state=42\n",
    "# 3. Print the resulting shapes of X_train, X_test, y_train, y_test to confirm they look correct\n",
    "\n",
    "\n",
    "\n",
    "# UNCOMMENT OUT BELOW AND RUN THE FOLLOWING TO MAKE SURE YOUR SPLIT LOOKS CORRECT\n",
    "# print(f\"X_train shape: {X_train.shape}\")\n",
    "# print(f\"X_test shape:  {X_test.shape}\")\n",
    "# print(f\"y_train shape: {y_train.shape}\")\n",
    "# print(f\"y_test shape:  {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0c210b",
   "metadata": {},
   "source": [
    "### **Task 2b: Scale the features using StandardScaler (10 points)**\n",
    "\n",
    "**Important:** Fit the scaler on the training data only, then transform both train and test.\n",
    "\n",
    "In a Markdown cell, explain in 1–2 sentences **why** we fit the scaler on training data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930ca369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# 1. Create a StandardScaler\n",
    "# 2. fit_transform on training features\n",
    "# 3. transform (NOT fit_transform!) on test features\n",
    "\n",
    "\n",
    "\n",
    "# UNCOMMENT OUT BELOW AND RUN THE FOLLOWING TO MAKE SURE YOUR SPLIT LOOKS CORRECT\n",
    "# print(\"Training data — mean and std after scaling:\")\n",
    "# print(X_train_scaled.describe().round(4).loc[['mean', 'std']])\n",
    "# print(\"\\nTest data — mean and std (should be CLOSE to 0/1 but not exact):\")\n",
    "# print(X_test_scaled.describe().round(4).loc[['mean', 'std']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03b2032",
   "metadata": {},
   "source": [
    "*YOUR EXPLANATION of why we fit on training data only:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c502395",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Exercise 3: Fit and Compare Three Models (30 points)**\n",
    "\n",
    "### **Task 3a: Fit Standard Linear Regression, Ridge, and Lasso (15 points)**\n",
    "\n",
    "Fit the following three models on the **scaled** training data:\n",
    "1. `LinearRegression()` — no regularization\n",
    "2. `Ridge(alpha=1.0)` — L2 regularization\n",
    "3. `Lasso(alpha=100.0, max_iter=10000)` — L1 regularization\n",
    "\n",
    "For each model, compute and print:\n",
    "- Training MSE\n",
    "- Test MSE\n",
    "- Test R² score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fc3d258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Fit all three models and print their performance metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d77321",
   "metadata": {},
   "source": [
    "### **Task 3b: Compare the coefficients (15 points)**\n",
    "\n",
    "Create a DataFrame showing the coefficients from all three models side by side (similar to what we did in the lecture). Then create a **bar chart** comparing them.\n",
    "\n",
    "In a Markdown cell, answer:\n",
    "1. Which features did Lasso zero out?\n",
    "2. Do the zeroed-out features make intuitive sense? Why or why not?\n",
    "3. How do the Ridge coefficients compare to OLS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e68d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# 1. Create a comparison DataFrame of coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa6c3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# 2. Create a bar chart visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8776dc4",
   "metadata": {},
   "source": [
    "*YOUR ANALYSIS HERE:*\n",
    "\n",
    "1. **Features Lasso zeroed out:** \n",
    "\n",
    "2. **Does this make intuitive sense?** \n",
    "\n",
    "3. **How do Ridge coefficients compare to OLS?** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac4ab06",
   "metadata": {},
   "source": [
    "---\n",
    "## **Exercise 4: Alpha Exploration (25 points)**\n",
    "\n",
    "### **Task 4a: Lasso coefficient paths (15 points)**\n",
    "\n",
    "Fit Lasso models with the following alphas: `[0.01, 0.1, 1, 10, 100, 1000, 10000, 50000, 100000]`\n",
    "\n",
    "Create a **Lasso coefficient path plot** (like in the lecture) showing how each feature's coefficient changes as alpha increases. Use `plt.xscale('log')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "53fa75bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# 1. Loop through alphas, fit Lasso, store coefficients\n",
    "# 2. Plot coefficient paths\n",
    "\n",
    "alphas = [0.01, 0.1, 1, 10, 100, 1_000, 10_000, 50_000, 100_000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03c3c28",
   "metadata": {},
   "source": [
    "### **Task 4b: Find the best alpha (10 points)**\n",
    "\n",
    "For each alpha above, compute the **Test MSE** and **Test R²** using **Lasso (L1) Regularization**. Which alpha gives the best test performance?\n",
    "\n",
    "Create a plot of **Test MSE vs. Alpha** to visualize the optimal point.\n",
    "\n",
    "Some Hints:\n",
    "- You can reuse the test MSE and R² code from before, but now loop through all alphas to find the best one.\n",
    "- The best alpha will be the one with the lowest Test MSE.\n",
    "- Don't forget to set `max_iter=10000`.\n",
    "- Use the Lecture Notes for examples of annotating plots.\n",
    "\n",
    "*(Note: Next week we'll learn the proper way to do this with Cross-Validation! For now, using the test set is fine for practice.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "669e0c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# 1. Compute Test MSE for each alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a13cab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# 2. Plot Test MSE vs Alpha\n",
    "# 3. Annotate the best alpha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d78153",
   "metadata": {},
   "source": [
    "*YOUR CONCLUSION: Which alpha performed best and why?*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82071906",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 5: Reflection Questions (10 points)\n",
    "\n",
    "Answer the following questions in Markdown. Each answer should be 2–4 sentences.\n",
    "\n",
    "**Q1 (2 points):** You're building a model to predict patient hospital readmission risk using 200 medical features collected from electronic health records. Many features might be irrelevant. Would you use Ridge or Lasso? Explain your reasoning.\n",
    "\n",
    "**Q2 (2 points):** A colleague says, *\"I ran Lasso and it zeroed out 'Age' so I removed it permanently from all future analyses.\"* What's potentially problematic about this reasoning?\n",
    "\n",
    "**Q3 (2 points):** Explain in your own words why feature scaling is required before applying Ridge or Lasso regression. What could go wrong if you skip scaling?\n",
    "\n",
    "**Q4 (4 points):** Connect tonight's lesson to the biblical principle from Luke 14:28 (our opening verse). How does regularization relate to the idea of \"counting the cost\" in model building?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a1a60e",
   "metadata": {},
   "source": [
    "*YOUR ANSWERS:*\n",
    "\n",
    "**Q1:** \n",
    "\n",
    "**Q2:** \n",
    "\n",
    "**Q3:** \n",
    "\n",
    "**Q4:** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caf3608",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Submission Checklist:**\n",
    "\n",
    "Before you submit your `.ipynb` file, please ensure you have completed the following:\n",
    "\n",
    "- [ ] **Data Prep:** Features are correctly split into X and y and a 80/20 train-test split has been performed with the random state set to 42.\n",
    "- [ ] **Feature Scaling:** `StandardScaler` has been applied to the training data (fit/transform) and test data (transform only).\n",
    "- [ ] **Model Implementation:** You have successfully fit a Standard Linear Regression, a Ridge model, and a Lasso model.\n",
    "- [ ] **Coefficient Analysis:** You have identified which feature Lasso \"zeroed out\" and explained why this happened.\n",
    "- [ ] **Alpha Experiment:** You have tested at least three different values of $\\alpha$ and observed the change in the number of non-zero coefficients.\n",
    "- [ ] **Final Check:** All code cells have been executed in order, and all visualizations (L1 vs L2 shapes) are visible.\n",
    "\n",
    "### **Submission Instructions**\n",
    "\n",
    "1. Save this notebook\n",
    "2. **Restart kernel and run all cells** (Kernel → Restart & Run All)\n",
    "3. Verify all outputs appear correctly (especially visualizations)\n",
    "4. Check that all written responses are complete\n",
    "5. Submit the `.ipynb` file to Canvas before Monday, 23 February @ 6:00 PM\n",
    "   - Grace period until Wednesday, 25 February @ 11:59 PM\n",
    "\n",
    "**Remember:** This notebook submission is worth 90% of your Week 4 Lab grade. The remaining 10% comes from next week's in-class mastery assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb6aaa7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Mastery Assessment Preparation Tips**\n",
    "\n",
    "* **The \"Complexity Tax\" Equation:** Be able to write the general objective function for regularized regression: $\\text{Total Cost} = \\text{RSS} + \\text{Penalty}$.\n",
    "* **L1 vs. L2 Differences:** \n",
    "    * Which one uses the absolute value of weights ($|w|$)? (Lasso/L1)\n",
    "    * Which one uses the square of weights ($w^2$)? (Ridge/L2)\n",
    "    * Which one is capable of setting coefficients to **exactly zero**? (Lasso/L1)\n",
    "* **The Geometry of Regularization:** Be able to identify the **Diamond** shape (Lasso) vs. the **Circle** shape (Ridge) and explain why the \"corners\" of the diamond lead to sparsity.\n",
    "* **Why Scale?** Be prepared to explain in one sentence why regularization fails if features (like \"number of rooms\" vs. \"square footage\") are not put on the same scale first.\n",
    "* **The Effect of Alpha ($\\alpha$):** If we increase $\\alpha$ to a very large number, what happens to the size of our coefficients? (They shrink toward zero)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py314",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
